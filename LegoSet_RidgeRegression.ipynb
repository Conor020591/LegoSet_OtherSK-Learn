{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c32d51b2",
   "metadata": {},
   "source": [
    "# Continuation of Lego Set Price Prediction\n",
    "Here we will go beyond a linear regression model and use a ridge regression model to see if a better model can be obtained with some regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8e79010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import category_encoders as ce\n",
    "from category_encoders import BinaryEncoder\n",
    "print('imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9968716c",
   "metadata": {},
   "source": [
    "Here we import the data generated from the LegoEDA project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a874c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       Unnamed: 0 Set_number                       Name Set_type       Theme  \\\n",
       "0            212      702-2            Small Basic Set   Normal   SAMSONITE   \n",
       "1            217      717-1         Junior Constructor   Normal   SAMSONITE   \n",
       "2            218      725-3                  Town Plan   Normal   SAMSONITE   \n",
       "3            279      450-2        Deluxe Building Set   Normal   SAMSONITE   \n",
       "4            281      615-1         Samsonite Gift Set   Normal   SAMSONITE   \n",
       "...          ...        ...                        ...      ...         ...   \n",
       "6787       19108    80043-1       Yellow Tusk Elephant   Normal  MONKIE KID   \n",
       "6788       19109    80044-1  Monkie Kid's Team Hideout   Normal  MONKIE KID   \n",
       "6789       19110    80045-1     Monkey King Ultra Mech   Normal  MONKIE KID   \n",
       "6790       19111    80110-1     Lunar New Year Display   Normal    SEASONAL   \n",
       "6791       19112    80111-1      Lunar New Year Parade   Normal    SEASONAL   \n",
       "\n",
       "           Theme_group                       Subtheme  Year_released  Pieces  \\\n",
       "0              Vintage                      BASIC SET         1961.0   109.0   \n",
       "1              Vintage                      BASIC SET         1961.0   510.0   \n",
       "2              Vintage                      TOWN PLAN         1961.0   711.0   \n",
       "3              Vintage                      BASIC SET         1963.0   450.0   \n",
       "4              Vintage                      BASIC SET         1963.0   615.0   \n",
       "...                ...                            ...            ...     ...   \n",
       "6787  Action/Adventure                       SEASON 4         2023.0   844.0   \n",
       "6788  Action/Adventure                       SEASON 4         2023.0  1582.0   \n",
       "6789  Action/Adventure                       SEASON 4         2023.0  1705.0   \n",
       "6790     Miscellaneous  CHINESE TRADITIONAL FESTIVALS         2023.0   872.0   \n",
       "6791     Miscellaneous  CHINESE TRADITIONAL FESTIVALS         2023.0  1653.0   \n",
       "\n",
       "      Minifigs   Price Age_range  \n",
       "0          0.0    1.95       NaN  \n",
       "1          0.0   16.95       NaN  \n",
       "2          0.0   25.00       NaN  \n",
       "3          0.0   10.95     4 - 9  \n",
       "4          0.0   14.95    5 - 10  \n",
       "...        ...     ...       ...  \n",
       "6787       5.0   79.99        8+  \n",
       "6788       6.0  139.99        9+  \n",
       "6789       6.0  159.99       10+  \n",
       "6790       0.0   89.99        8+  \n",
       "6791      18.0  129.99        8+  \n",
       "\n",
       "[6792 rows x 12 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in clean data\n",
    "lego_mod_df = pd.read_csv('legoData_mod.csv')\n",
    "lego_mod_df.head\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d1de64",
   "metadata": {},
   "source": [
    "Just a reminder of what the data looks like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e5244f",
   "metadata": {},
   "source": [
    "## Split to features and target and also make validation set\n",
    "also going to shuffle the dataset and saved the shuffled set for use in other projects for comparisson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1901dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "lego_mod_df = lego_mod_df.sample(frac = 1)\n",
    "train_set, val_set = train_test_split(lego_mod_df, test_size=0.2, random_state=0)\n",
    "\n",
    "y = train_set.Price\n",
    "X = train_set.drop(['Price'], axis=1)\n",
    "\n",
    "\n",
    "y_val = val_set.Price\n",
    "X_val = val_set.drop(['Price'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14b12ce",
   "metadata": {},
   "source": [
    "## Define model function\n",
    "As in the Linear Regression I will define a function to test the model.\n",
    "While this could be done inline, I can leave other scoring parameters commented out, so that I can uncomment them if I want to see them here. And as a result it cuts down on lines and keeps my tests tidier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59dabf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "def linear_model(preprocessor,X,y):    \n",
    "    model = Ridge(alpha=0.1, solver=\"cholesky\")\n",
    "    model = RidgeCV()\n",
    "    my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', model)\n",
    "                             ])\n",
    "    \n",
    "    scoring = ['r2','neg_root_mean_squared_error']\n",
    "    scores = cross_validate(my_pipeline, X, y,\n",
    "                              cv=5,\n",
    "                              scoring=scoring,\n",
    "                              return_train_score=True)\n",
    "\n",
    "#    print(\"mean r2: train = \"+str(scores['train_r2'].mean())+\", test = \"+str(scores['test_r2'].mean()))\n",
    "#    print(\"mean RMSE: train = \"+str(-1*scores['train_neg_root_mean_squared_error'].mean())+\", test = \"+str(-1*scores['test_neg_root_mean_squared_error'].mean()))\n",
    "   \n",
    "    return -1*scores['test_neg_root_mean_squared_error'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbfe0ef",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "### Numerical Data\n",
    "I will preprocess the numerical data in the same was as in the Linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cb25f2",
   "metadata": {},
   "source": [
    "Next I add in minifigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f435465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.067572361242394"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler  = preprocessing.StandardScaler()\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', scaler, ['Pieces','Minifigs','Year_released']),\n",
    "    ],\n",
    "    remainder = 'drop'\n",
    ")\n",
    "\n",
    "linear_model(preprocessor,X,y)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391160fc",
   "metadata": {},
   "source": [
    "Adding polynomials to see if they improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34b573e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.104977157737647"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler  = preprocessing.StandardScaler()\n",
    "polyn = preprocessing.PolynomialFeatures(2) \n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scale', scaler),\n",
    "    ('poly', polyn)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', numerical_transformer, ['Pieces','Minifigs','Year_released']),\n",
    "        \n",
    "    ],\n",
    "    remainder = 'drop'\n",
    ")\n",
    "\n",
    "linear_model(preprocessor,X,y)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58643c09",
   "metadata": {},
   "source": [
    "Again, 2nd order polynomials decrease RMSE the most."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35295974",
   "metadata": {},
   "source": [
    "#### Categorical Data\n",
    "Next we will look at the categorical data.\n",
    "\n",
    "Some of these features have many unique variables, whereas some have few, as such I will test to see which are better candidates for onehot, binary and target encoding. Below is a function which tests a given feature's test RMSE and outputs which type of encoding lowers the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b16dbc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "from category_encoders import BinaryEncoder\n",
    "def cat_tester(feat,full_numerical_transformer,  X, y):\n",
    "    BI_categorical_transformer = Pipeline(steps=[\n",
    "        ('Binary', BinaryEncoder(return_df=True))\n",
    "\n",
    "    ])\n",
    "    OH_categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', drop = 'first'))\n",
    "\n",
    "    ])\n",
    "\n",
    "    TAR_categorical_transformer = Pipeline(steps=[\n",
    "        ('Target', TargetEncoder())\n",
    "\n",
    "    ])\n",
    "    Encoder_Array = [OH_categorical_transformer, BI_categorical_transformer, TAR_categorical_transformer]\n",
    "    Encoder_names = [\"OneHot\",\"Binary\", \"Target\",]\n",
    "    lowest =0\n",
    "    lowest_name =''\n",
    "    for i, (encoder,encoderName) in enumerate(zip(Encoder_Array,Encoder_names)):\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                        full_numerical_transformer,\n",
    "                      ('test_cat', encoder, [feat]),\n",
    "\n",
    "            ],\n",
    "            remainder = 'drop'\n",
    "    )\n",
    "\n",
    "        rmse_score = linear_model(preprocessor,X,y)\n",
    "        if i==0:\n",
    "            lowest_name =encoderName\n",
    "            lowest = rmse_score\n",
    "        elif lowest > rmse_score:\n",
    "            lowest_name =encoderName\n",
    "            lowest = rmse_score\n",
    "#        print(encoderName+\": \"+ str(rmse_score))\n",
    "    return lowest_name, lowest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d597830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set_type: OneHot = 28.09951268647747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theme: OneHot = 23.118731070021433\n",
      "Theme_group: OneHot = 25.452087498307083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtheme: OneHot = 26.38661474503096\n"
     ]
    }
   ],
   "source": [
    "cat_feats = [ 'Set_type', 'Theme', 'Theme_group', 'Subtheme']\n",
    "for feat in cat_feats:\n",
    "    encoder  = cat_tester(feat,full_numerical_transformer,X,y)\n",
    "    print(feat + ': ' +encoder[0] + ' = ' + str(encoder[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1040db7f",
   "metadata": {},
   "source": [
    "This calls for OneHot encoding as the method for all of the categorical data. I am a little worried about overfitting given all of the extra features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6064a8a",
   "metadata": {},
   "source": [
    "The below run specifies our new best model (this actually excludes subtheme from the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d8a40fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [1, 2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [1, 2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [1, 2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [1, 2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22.692194113881392"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best Run\n",
    "OH_categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop = 'first'))\n",
    "    \n",
    "])\n",
    "\n",
    "TAR_categorical_transformer = Pipeline(steps=[\n",
    "    ('Target', ce.TargetEncoder())\n",
    "    \n",
    "])\n",
    "BI_categorical_transformer = Pipeline(steps=[\n",
    "    ('Binary', BinaryEncoder(return_df=True))\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', numerical_transformer, ['Pieces','Minifigs','Year_released']),\n",
    "       #           ('BI_cat', BI_categorical_transformer, ['Set_type']),\n",
    "      #            ('TAR_cat', TAR_categorical_transformer, ['Subtheme','Set_type']),\n",
    "                  ('OH_cat', OH_categorical_transformer, ['Theme_group', 'Theme','Subtheme','Set_type'])\n",
    "    ],\n",
    "    remainder = 'drop'\n",
    ")\n",
    "\n",
    "linear_model(preprocessor,X,y)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1289e5ca",
   "metadata": {},
   "source": [
    "At this point the training RMSE is higher than the linear model. \n",
    "\n",
    "But let's run a prediction on the validation set, training on the full trianing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6caf8d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17.622699068868133"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', RidgeCV())\n",
    "                             ])\n",
    "my_pipeline.fit(X, y)\n",
    "y_preds = my_pipeline.predict(X_val)\n",
    "np.sqrt(mean_squared_error(y_val, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e67826",
   "metadata": {},
   "source": [
    "This turns out to be better than the linear model on the validation set. The extra columns from the one-hot encoding must not be overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674ac8da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
