{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c32d51b2",
   "metadata": {},
   "source": [
    "# Continuation of Lego Set Price Prediction\n",
    "Here we will go beyond a linear regression model and use a ridge regression model to see if a better model can be obtained with some regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e79010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import category_encoders as ce\n",
    "from category_encoders import BinaryEncoder\n",
    "print('imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9968716c",
   "metadata": {},
   "source": [
    "Here we import the data generated from the LegoEDA project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a874c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in clean data\n",
    "lego_train_df = pd.read_csv('../LegoSet_EDA_DataClean/legoData_train.csv')\n",
    "lego_val_df = pd.read_csv('../LegoSet_EDA_DataClean/legoData_val.csv')\n",
    "\n",
    "\n",
    "y = lego_train_df.Price\n",
    "X = lego_train_df.drop(['Price'], axis=1)\n",
    "\n",
    "\n",
    "y_val = lego_val_df.Price\n",
    "X_val = lego_val_df.drop(['Price'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14b12ce",
   "metadata": {},
   "source": [
    "## Define model function\n",
    "As in the Linear Regression I will define a function to test the model.\n",
    "While this could be done inline, I can leave other scoring parameters commented out, so that I can uncomment them if I want to see them here. And as a result it cuts down on lines and keeps my tests tidier.\n",
    "\n",
    "Here I use RidgeCV in order to find the best value for alpha, and the best solver. While this adds some computation, finding the best value every time. In this particular case there isn't much time added to the runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59dabf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "def linear_model(preprocessor,X,y):    \n",
    "    model = RidgeCV()\n",
    "    my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', model)\n",
    "                             ])\n",
    "    \n",
    "    scoring = ['r2','neg_root_mean_squared_error']\n",
    "    scores = cross_validate(my_pipeline, X, y,\n",
    "                              cv=5,\n",
    "                              scoring=scoring,\n",
    "                              return_train_score=True)\n",
    "\n",
    "#    print(\"mean r2: train = \"+str(scores['train_r2'].mean())+\", test = \"+str(scores['test_r2'].mean()))\n",
    "#    print(\"mean RMSE: train = \"+str(-1*scores['train_neg_root_mean_squared_error'].mean())+\", test = \"+str(-1*scores['test_neg_root_mean_squared_error'].mean()))\n",
    "   \n",
    "    return -1*scores['test_neg_root_mean_squared_error'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbfe0ef",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "### Numerical Data\n",
    "I will preprocess the numerical data in the same was as in the Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f435465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.152885955603075"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler  = preprocessing.StandardScaler()\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', scaler, ['Pieces','Minifigs','Year_released']),\n",
    "    ],\n",
    "    remainder = 'drop'\n",
    ")\n",
    "\n",
    "linear_model(preprocessor,X,y)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391160fc",
   "metadata": {},
   "source": [
    "Adding polynomials to see if they improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34b573e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.371752500619227"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler  = preprocessing.StandardScaler()\n",
    "polyn = preprocessing.PolynomialFeatures(4) \n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scale', scaler),\n",
    "    ('poly', polyn)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', numerical_transformer, ['Pieces','Minifigs','Year_released']),\n",
    "        \n",
    "    ],\n",
    "    remainder = 'drop'\n",
    ")\n",
    "\n",
    "linear_model(preprocessor,X,y)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58643c09",
   "metadata": {},
   "source": [
    "Here, fourth order polynomials reduce the RMSE the most"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35295974",
   "metadata": {},
   "source": [
    "#### Categorical Data\n",
    "Next we will look at the categorical data.\n",
    "\n",
    "Some of these features have many unique variables, whereas some have few, as such I will test to see which are better candidates for onehot, binary and target encoding. Below is a function which tests a given feature's test RMSE and outputs which type of encoding lowers the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b16dbc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "from category_encoders import BinaryEncoder\n",
    "def cat_tester(feat,full_numerical_transformer,  X, y):\n",
    "    BI_categorical_transformer = Pipeline(steps=[\n",
    "        ('Binary', BinaryEncoder(return_df=True))\n",
    "\n",
    "    ])\n",
    "    OH_categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', drop = 'first'))\n",
    "\n",
    "    ])\n",
    "\n",
    "    TAR_categorical_transformer = Pipeline(steps=[\n",
    "        ('Target', TargetEncoder())\n",
    "\n",
    "    ])\n",
    "    Encoder_Array = [OH_categorical_transformer, BI_categorical_transformer, TAR_categorical_transformer]\n",
    "    Encoder_names = [\"OneHot\",\"Binary\", \"Target\",]\n",
    "    lowest =0\n",
    "    lowest_name =''\n",
    "    for i, (encoder,encoderName) in enumerate(zip(Encoder_Array,Encoder_names)):\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                    \n",
    "                    full_numerical_transformer, \n",
    "                      ('test_cat', encoder, [feat]),\n",
    "\n",
    "            ],\n",
    "            remainder = 'drop'\n",
    "        )\n",
    "\n",
    "        rmse_score = linear_model(preprocessor,X,y)\n",
    "        if i==0:\n",
    "            lowest_name =encoderName\n",
    "            lowest = rmse_score\n",
    "        elif lowest > rmse_score:\n",
    "            lowest_name =encoderName\n",
    "            lowest = rmse_score\n",
    "#        print(encoderName+\": \"+ str(rmse_score))\n",
    "    return lowest_name, lowest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d597830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set_type: Target = 28.46266404058149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theme: OneHot = 23.130312594258232\n",
      "Theme_group: OneHot = 25.582229171994037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtheme: OneHot = 26.206051851133147\n"
     ]
    }
   ],
   "source": [
    "scaler  = preprocessing.StandardScaler()\n",
    "polyn = preprocessing.PolynomialFeatures(2) \n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scale', scaler),\n",
    "    ('poly', polyn)\n",
    "])\n",
    "\n",
    "full_numerical_transformer = ('num', numerical_transformer, ['Pieces','Minifigs','Year_released'])\n",
    "\n",
    "cat_feats = [ 'Set_type', 'Theme', 'Theme_group', 'Subtheme']\n",
    "for feat in cat_feats:\n",
    "    encoder  = cat_tester(feat,full_numerical_transformer,X,y)\n",
    "    print(feat + ': ' +encoder[0] + ' = ' + str(encoder[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1040db7f",
   "metadata": {},
   "source": [
    "This calls for OneHot encoding as the method for all of the categorical data, except set type. I am a little worried about overfitting given all of the extra features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6064a8a",
   "metadata": {},
   "source": [
    "The below run specifies our new best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d8a40fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [1, 2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [1, 2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [1, 2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [1, 2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21.33419911456054"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best Run\n",
    "OH_categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop = 'first'))\n",
    "    \n",
    "])\n",
    "\n",
    "TAR_categorical_transformer = Pipeline(steps=[\n",
    "    ('Target', ce.TargetEncoder())\n",
    "    \n",
    "])\n",
    "BI_categorical_transformer = Pipeline(steps=[\n",
    "    ('Binary', BinaryEncoder(return_df=True))\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', numerical_transformer, ['Pieces','Minifigs','Year_released']),\n",
    "        #          ('BI_cat', BI_categorical_transformer, ['Set_type']),\n",
    "                  ('TAR_cat', TAR_categorical_transformer, ['Set_type']),\n",
    "                  ('OH_cat', OH_categorical_transformer, ['Theme_group', 'Theme','Subtheme'])\n",
    "    ],\n",
    "    remainder = 'drop'\n",
    ")\n",
    "\n",
    "linear_model(preprocessor,X,y)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1289e5ca",
   "metadata": {},
   "source": [
    "Now that we have our encodings finalized, time to run a prediction on the validation set, training on the full training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6caf8d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [1, 2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18.605899004842534"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', RidgeCV())\n",
    "                             ])\n",
    "my_pipeline.fit(X, y)\n",
    "y_preds = my_pipeline.predict(X_val)\n",
    "np.sqrt(mean_squared_error(y_val, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e67826",
   "metadata": {},
   "source": [
    "RMSE of 18.605899004842534 turns out to be better than the linear model on the validation set. The extra columns from the one-hot encoding must not be overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674ac8da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
